{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-14T15:02:59.315741Z",
     "start_time": "2025-09-14T15:02:59.141251Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:04:55.492173Z",
     "start_time": "2025-09-14T15:04:55.487484Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('./100_Unique_QA_Dataset.csv')",
   "id": "46c94200a09a1819",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:04:58.612452Z",
     "start_time": "2025-09-14T15:04:58.604524Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "34c92284b25a166c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                          question      answer\n",
       "0                   What is the capital of France?       Paris\n",
       "1                  What is the capital of Germany?      Berlin\n",
       "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
       "3  What is the largest planet in our solar system?     Jupiter\n",
       "4   What is the boiling point of water in Celsius?         100"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:06:51.912032Z",
     "start_time": "2025-09-14T15:06:51.909089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#tokenize each word\n",
    "def token(text):\n",
    "    text = text.lower()\n",
    "    text= text.replace('?', '')\n",
    "    text= text.replace(\"'\", \"\")\n",
    "    return text.split()"
   ],
   "id": "d44c213c9ad35815",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:07:23.117539Z",
     "start_time": "2025-09-14T15:07:23.115131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#vocabulary\n",
    "vocab = {'<UNK>':0}"
   ],
   "id": "e4e82aa94d90adb6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:11:19.002795Z",
     "start_time": "2025-09-14T15:11:18.999692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def buildvocab(row):\n",
    "    tokenizequestion = token(row['question'])\n",
    "    tokenizeanswer = token(row['answer'])\n",
    "    merge = tokenizequestion + tokenizeanswer\n",
    "    # print(merge)\n",
    "    for tokens in merge:\n",
    "        if tokens not in vocab:\n",
    "            vocab[tokens] = len(vocab)"
   ],
   "id": "5c29d30eec41a9b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:11:19.339571Z",
     "start_time": "2025-09-14T15:11:19.335017Z"
    }
   },
   "cell_type": "code",
   "source": "df.apply(buildvocab, axis=1)",
   "id": "ed037d52f7864ed1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:14:30.088108Z",
     "start_time": "2025-09-14T15:14:30.084398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def texttoindices(text,vocab):\n",
    "    indtxt=[]\n",
    "    for tokens in token(text):\n",
    "        if tokens in vocab:\n",
    "            indtxt.append(vocab[tokens])\n",
    "        else:\n",
    "            indtxt.append(vocab['<UNK>'])\n",
    "    return indtxt"
   ],
   "id": "e5bfd898c5e5a587",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:14:38.015496Z",
     "start_time": "2025-09-14T15:14:38.011897Z"
    }
   },
   "cell_type": "code",
   "source": "texttoindices('what is ert',vocab)",
   "id": "ef94adabd62db3fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:16:12.395783Z",
     "start_time": "2025-09-14T15:16:12.393503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset"
   ],
   "id": "ed7722e0cec53ed8",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:17:53.088376Z",
     "start_time": "2025-09-14T15:17:53.085140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QAdataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        numericalquestion = texttoindices(self.df.iloc[idx]['question'],self.vocab)\n",
    "        numericalanswer = texttoindices(self.df.iloc[idx]['answer'],self.vocab)\n",
    "        return torch.tensor(numericalquestion),torch.tensor(numericalanswer)"
   ],
   "id": "6edff8d9020a10b4",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:18:08.438054Z",
     "start_time": "2025-09-14T15:18:08.436294Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = QAdataset(df,vocab)",
   "id": "499b18f8cb3e5107",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:18:23.109126Z",
     "start_time": "2025-09-14T15:18:23.106777Z"
    }
   },
   "cell_type": "code",
   "source": "dataloader = DataLoader(dataset,batch_size=1,shuffle=True)",
   "id": "87e551b2725dc66a",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:18:53.140464Z",
     "start_time": "2025-09-14T15:18:53.138619Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "36d48097eb62954e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:20:45.534895Z",
     "start_time": "2025-09-14T15:20:45.532859Z"
    }
   },
   "cell_type": "code",
   "source": "import torch.nn as nn",
   "id": "d96c960aec2cb84a",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:37:45.520772Z",
     "start_time": "2025-09-14T15:37:45.517184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.embed=nn.Embedding(vocab_size,embedding_dim=50)\n",
    "        self.rnn = nn.RNN(50,64,batch_first=True)# batch first is made true bcz we need 1,1,324 as ouput in next layer else we will get error\n",
    "        self.out = nn.Linear(64,vocab_size)\n",
    "    def forward(self,question):\n",
    "        q = self.embed(question)\n",
    "        hidden,final = self.rnn(q)\n",
    "        output = self.out(final.squeeze(0))# squeezing the final layer so that we can get 1,324 which has only one dimension of final output\n",
    "        return output\n"
   ],
   "id": "16e51ec890beffee",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:37:46.196492Z",
     "start_time": "2025-09-14T15:37:46.194401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = 0.001\n",
    "epochs = 20"
   ],
   "id": "2f513fdb5affc774",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:37:46.561127Z",
     "start_time": "2025-09-14T15:37:46.557272Z"
    }
   },
   "cell_type": "code",
   "source": "model = RNN(len(vocab))",
   "id": "47dcb76d4c6e81c9",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:37:47.481539Z",
     "start_time": "2025-09-14T15:37:47.478891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criteri = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)"
   ],
   "id": "a29f5eb3a94c3ec3",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:38:03.741646Z",
     "start_time": "2025-09-14T15:38:02.746937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(epochs):\n",
    "    totalloss =0\n",
    "    for q,ans in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(q)\n",
    "        loss = criteri(outputs,ans[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        totalloss += loss.item()\n",
    "    print(f'epoch {epoch}, total loss: {totalloss/len(dataloader)}')"
   ],
   "id": "28438f3756fb32e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, total loss: 0.11130448633597957\n",
      "epoch 1, total loss: 0.09779223824540774\n",
      "epoch 2, total loss: 0.0864603472666608\n",
      "epoch 3, total loss: 0.0771029078712066\n",
      "epoch 4, total loss: 0.0691293389019039\n",
      "epoch 5, total loss: 0.06223727423283789\n",
      "epoch 6, total loss: 0.056163932445148626\n",
      "epoch 7, total loss: 0.05108973539123932\n",
      "epoch 8, total loss: 0.046619675784475276\n",
      "epoch 9, total loss: 0.04274657995750507\n",
      "epoch 10, total loss: 0.039196566575103335\n",
      "epoch 11, total loss: 0.03606103153692351\n",
      "epoch 12, total loss: 0.033253708937101896\n",
      "epoch 13, total loss: 0.030773752513859005\n",
      "epoch 14, total loss: 0.02850962748958005\n",
      "epoch 15, total loss: 0.026466217761238416\n",
      "epoch 16, total loss: 0.024630223411238855\n",
      "epoch 17, total loss: 0.022986217971063323\n",
      "epoch 18, total loss: 0.021413168062766393\n",
      "epoch 19, total loss: 0.02004377781930897\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:48:00.335791Z",
     "start_time": "2025-09-14T15:48:00.331822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(model,question,th=0.5):\n",
    "    q = texttoindices(question,vocab)\n",
    "    qtensor = torch.tensor(q).unsqueeze(0)#converting into tensor and unsqueezing it to add dimension\n",
    "    outputs = model(qtensor) # we get logits as outputs here\n",
    "    prob = torch.nn.functional.softmax(outputs, dim=1) # using softmax to get prob of logits\n",
    "    value ,index = torch.max(prob,dim=1) # find index of max prob\n",
    "    if value.item() < th:\n",
    "        print('no answer')\n",
    "    print(list(vocab.keys())[index])\n"
   ],
   "id": "82a0fcbe864ee5bb",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T15:48:11.166144Z",
     "start_time": "2025-09-14T15:48:11.162375Z"
    }
   },
   "cell_type": "code",
   "source": "predict(model,'what is capital of india')",
   "id": "728f58b941a5b0a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delhi\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7527325f26ae43a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
